{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import timm\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    handlers=[logging.FileHandler('swin_transformer_384_class_3_notebook.log'), logging.StreamHandler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "\n",
    "    @staticmethod\n",
    "    def set_seed(SEED):\n",
    "        os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "        random.seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def set_path(root_path):\n",
    "        train_path = f'{root_path}/train/'\n",
    "        test_path = f'{root_path}/test/'\n",
    "\n",
    "        return root_path, train_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.set_seed(0xC0FFE)\n",
    "root_path, train_path, test_path = CONFIG.set_path('/root/Project/new_data')\n",
    "\n",
    "logging.info('1. Set Seed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df.iloc[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "logging.info('2. Define Dataset Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 및 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'swin_large_patch4_window12_384'  # 모델명\n",
    "img_size = 384\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "patience = 3\n",
    "T_0 = 5\n",
    "T_mult = 2\n",
    "eta_min = 1e-6\n",
    "accumulation_steps = 4  # 그래디언트 누적 스텝 수\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size, always_apply=True), \n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=(255, 255, 255)), \n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "logging.info('3. Set Hyperparameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 로드 및 클래스 할당\n",
    "train_file = pd.read_csv(f'{root_path}/combined_data.csv')\n",
    "train_file['class'] = None\n",
    "\n",
    "train_file.loc[train_file['target'].isin([0, 5, 8, 9]), 'class'] = 0\n",
    "train_file.loc[train_file['target'].isin([2, 16]), 'class'] = 1\n",
    "train_file.loc[train_file['target'].isin([1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15]), 'class'] = 2\n",
    "\n",
    "\n",
    "# 훈련 데이터셋 생성 및 로더 설정\n",
    "train_datasets = {cls: ImageDataset(df=train_file[train_file['class'] == cls], \n",
    "                                    path=train_path, \n",
    "                                    transform=train_transform) \n",
    "                  for cls in range(3)}\n",
    "\n",
    "train_loaders = {cls: DataLoader(dataset, batch_size=batch_size, shuffle=True) \n",
    "                 for cls, dataset in train_datasets.items()}\n",
    "\n",
    "logging.info('4. Load Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class가 2인 paper class에 대해서만 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = train_file.loc[train_file['class'] == 2, ['ID', 'target']]\n",
    "class_dataset = train_datasets[2]\n",
    "class_loader = train_loaders[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "class_file.loc[class_file['target'] == 1, 'target'] = 0\n",
    "class_file.loc[class_file['target'] == 3, 'target'] = 1\n",
    "class_file.loc[class_file['target'] == 4, 'target'] = 2\n",
    "class_file.loc[class_file['target'] == 6, 'target'] = 3\n",
    "class_file.loc[class_file['target'] == 7, 'target'] = 4\n",
    "class_file.loc[class_file['target'] == 10, 'target'] = 5\n",
    "class_file.loc[class_file['target'] == 11, 'target'] = 6\n",
    "class_file.loc[class_file['target'] == 12, 'target'] = 7\n",
    "class_file.loc[class_file['target'] == 13, 'target'] = 8\n",
    "class_file.loc[class_file['target'] == 14, 'target'] = 9\n",
    "class_file.loc[class_file['target'] == 15, 'target'] = 10\n",
    "class_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할된 데이터를 fold별로 시각화하기 위한 함수를 구성합니다.\n",
    "# Scikit-learn에서 https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html 사용한 코드를 가져와서 사용하겠습니다.\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def plot_cv_indices(x, y, cv, ax, split_strategy='KFold', group=None, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=x, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        # print(f\"Fold {ii} :\")\n",
    "        # print(f\"  Train : index={tr[:5]}...\")\n",
    "        # print(f\"  Valid : index={tt[:5]}...\")\n",
    "        indices = np.array([np.nan] * len(x))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=0.2,\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(5))\n",
    "\n",
    "    ax.set(\n",
    "        yticks=np.arange(len(yticklabels)) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[len(yticklabels) + 0.2, -0.2],\n",
    "        xlim=[0, len(x)],\n",
    "    )\n",
    "    ax.set_title(split_strategy, fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "fig, ax = plt.subplots()\n",
    "plot_cv_indices(x=class_file['ID'],\n",
    "                y=class_file['target'],\n",
    "                cv=skf,\n",
    "                ax=ax,\n",
    "                split_strategy='Stratified K-Fold')\n",
    "\n",
    "train_folds = skf.split(class_file['ID'], class_file['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def _train_one_epoch(loader, model, optimizer, loss_fn, scheduler, scaler, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for index, (images, targets) in enumerate(pbar):\n",
    "\n",
    "        if (index + 1) % 50 == 0:\n",
    "            logging.info(f'Batch count: {index + 1} / {len(pbar)}')\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast():\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 일정 배치마다 역전파 수행 및 가중치 업데이트\n",
    "        if (index + 1) % accumulation_steps == 0 or (index + 1) == len(loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def _val_one_epoch(loader, model, device):\n",
    "    model.eval()\n",
    "    \n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(class_file['target']), y=class_file['target'])\n",
    "print(class_weights)\n",
    "\n",
    "alpha = torch.tensor(class_weights, dtype=torch.float64).to(device)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # alpha 값을 targets의 크기에 맞게 브로드캐스팅\n",
    "        alpha = self.alpha.gather(0, targets.long())\n",
    "\n",
    "        focal_loss = alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            focal_loss = focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            focal_loss = focal_loss.sum()\n",
    "        return focal_loss\n",
    "    \n",
    "# loss_fn = FocalLoss(alpha=alpha, gamma=2)\n",
    "logging.info('5. Define Focal Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta(model, loader, device):\n",
    "    model.eval()\n",
    "    final_preds = []\n",
    "    rot_transform = A.Compose([\n",
    "        A.Rotate(limit=(0, 0), p=1.0, border_mode=cv2.BORDER_CONSTANT, value=(1, 1, 1))\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "            flipped_images = torch.flip(images, dims=[3])\n",
    "            outputs_flipped = model(flipped_images)\n",
    "            probabilities_flipped = torch.nn.functional.softmax(outputs_flipped, dim=1)\n",
    "\n",
    "            rotations = [30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]\n",
    "            rotated_probabilities = []\n",
    "            for angle in rotations:\n",
    "                rot_transform.transforms[0].limit = (angle, angle)\n",
    "                rotated_images = []\n",
    "                for img in images:\n",
    "                    img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "                    rotated_img = rot_transform(image=img_np)['image']\n",
    "                    rotated_img_tensor = torch.from_numpy(rotated_img).permute(2, 0, 1).to(device)\n",
    "                    rotated_images.append(rotated_img_tensor)\n",
    "                rotated_images = torch.stack(rotated_images)\n",
    "\n",
    "                outputs_rotated = model(rotated_images)\n",
    "                probabilities_rotated = torch.nn.functional.softmax(outputs_rotated, dim=1)\n",
    "                rotated_probabilities.append(probabilities_rotated)\n",
    "\n",
    "            averaged_probabilities = (probabilities + probabilities_flipped + sum(rotated_probabilities)) / (len(rotations) + 2)\n",
    "            # preds = averaged_probabilities.argmax(dim=1)\n",
    "            final_preds.extend(averaged_probabilities.cpu().numpy())\n",
    "    return final_preds\n",
    "\n",
    "logging.info('6. Define Test Time Augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(patience, num_epochs, device):\n",
    "\n",
    "    # 시작 시간\n",
    "    since = time.time()\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    for fold_index, (train_index, validation_index) in enumerate(train_folds):\n",
    "\n",
    "        # 그라디언트 스케일러 초기화\n",
    "        scaler = GradScaler()\n",
    "  \n",
    "        print()\n",
    "        print(f'Stratified K-Fold: {fold_index}')\n",
    "        logging.info(f'Stratified K-Fold: {fold_index + 1} / 5')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model = timm.create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=True,\n",
    "            # 11개\n",
    "            num_classes=11\n",
    "        ).to(device)\n",
    "\n",
    "        loss_fn = FocalLoss(alpha=alpha, gamma=2)\n",
    "        optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=T_mult, eta_min=eta_min)\n",
    "        \n",
    "        # train\n",
    "        train_data = class_file.iloc[train_index, :]\n",
    "        train_dataset = ImageDataset(\n",
    "            df=train_data,\n",
    "            path=train_path,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        # validation\n",
    "        validation_data = class_file.iloc[validation_index, :]\n",
    "        validation_dataset = ImageDataset(\n",
    "            df=validation_data,\n",
    "            path=train_path,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        validation_loader = DataLoader(\n",
    "            validation_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        best_epoch = 0\n",
    "        best_f1_score = 0\n",
    "        early_stop_counter = 0\n",
    "        best_model_weights = None\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            logging.info(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "            if early_stop_counter >= patience:\n",
    "                logging.info(f\"Early Stopping... epoch {epoch + 1}\")\n",
    "                print(\"Early Stopping....\\n\")\n",
    "                break\n",
    "\n",
    "            # train\n",
    "            ret = _train_one_epoch(train_loader, model, optimizer, loss_fn, scheduler, scaler, device)\n",
    "            # validation\n",
    "            ret2, val_f1 = _val_one_epoch(validation_loader, model, device)\n",
    "\n",
    "            print(f\"Loss: {ret['train_loss']:.4f}, train Accuracy: {ret['train_acc']:.4f}, train F1-Score: {ret['train_f1']:.4f}\")\n",
    "            print(f\"validation Accuracy: {ret2['train_acc']:.4f}, validation F1-Score: {ret2['train_f1']:.4f}\")\n",
    "            print('-' * 10)\n",
    "            \n",
    "            # f1-score을 비교\n",
    "            if val_f1 > best_f1_score:\n",
    "                early_stop_counter = 0\n",
    "\n",
    "                best_epoch = epoch\n",
    "                best_f1_score = val_f1\n",
    "                best_model_weights = model.state_dict()\n",
    "                \n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "    \n",
    "        print(f'best epoch: {best_epoch}, best f1 score: {best_f1_score}')\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "        # 가장 좋은 모델의 가중치(w) 가져오기\n",
    "        model.load_state_dict(best_model_weights)\n",
    "    \n",
    "        model_path = f'{root_path}/model/{model_name}_class_3'\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "\n",
    "        with open(f'{model_path}/fold_{fold_index}' + '.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        models.append({\n",
    "            'model': model,\n",
    "            'weights': best_model_weights,\n",
    "            'f1_score': best_f1_score,\n",
    "        })\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('7. Start Training')\n",
    "logging.info('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련하기\n",
    "models = train_model(patience, num_epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.info('----------------------------------------------')\n",
    "logging.info('8. Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "models = []\n",
    "\n",
    "for i in range(5):\n",
    "    with open(f'{root_path}/model/{model_name}_all/fold_{i}.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier로 나눈 3개의 클래스 중 class 2에 해당하는 row들만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 결과 csv 불러오기\n",
    "classfier_result = pd.read_csv(f'{root_path}/efficientnet_b5.sw_in12k_ft_in1k class.csv')\n",
    "\n",
    "\n",
    "test_file = pd.read_csv(f'{root_path}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_class_2 = test_file.loc[classfier_result['class'] == 2]\n",
    "test_file_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset(\n",
    "    df=test_file_class_2,\n",
    "    path=test_path,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = f\"{root_path}/result\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "# Soft Voting\n",
    "ensemble_preds_soft = []\n",
    "for model in models:\n",
    "    # shape (model 수, test data 이미지 수, class 수)\n",
    "    ensemble_preds_soft.append(tta(model, test_loader, device))\n",
    "    \n",
    "# shape (test data 이미지 수, class 수)\n",
    "ensemble_preds_soft = np.mean(ensemble_preds_soft, axis=0)\n",
    "# shape (test data 이미지 수)\n",
    "final_preds_soft = np.argmax(ensemble_preds_soft, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = final_preds_soft\n",
    "logging.info('9. Predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "# 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15 으로 다시 복구\n",
    "pred_df.loc[pred_df['target'] == 0, 'target'] = 1\n",
    "pred_df.loc[pred_df['target'] == 1, 'target'] = 3\n",
    "pred_df.loc[pred_df['target'] == 2, 'target'] = 4\n",
    "pred_df.loc[pred_df['target'] == 3, 'target'] = 6\n",
    "pred_df.loc[pred_df['target'] == 4, 'target'] = 7\n",
    "pred_df.loc[pred_df['target'] == 5, 'target'] = 10\n",
    "pred_df.loc[pred_df['target'] == 6, 'target'] = 11\n",
    "pred_df.loc[pred_df['target'] == 7, 'target'] = 12\n",
    "pred_df.loc[pred_df['target'] == 8, 'target'] = 13\n",
    "pred_df.loc[pred_df['target'] == 9, 'target'] = 14\n",
    "pred_df.loc[pred_df['target'] == 10, 'target'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (test_file_class_2['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = f\"{root_path}/result\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "pred_df.to_csv(f\"{result_path}/{model_name}_class_3.csv\", index=False)\n",
    "pred_df.head()\n",
    "logging.info('Finish!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
